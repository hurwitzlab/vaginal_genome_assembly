{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04de998a",
   "metadata": {},
   "source": [
    "# 00: Getting started (LSF)\n",
    "\n",
    "## Job Arrays\n",
    "All the notebooks in this repository show you how to run the analysis using **job arrays**. Job arrays are a way to run the same job multiple times with different input files. This is useful for running the same analysis on multiple samples, as is often the case in bioinformatics. \n",
    "\n",
    "Our basic **job array submission structure** requires the following files: \n",
    "- A text file (e.g. `sample_list.txt`) that contains a list of input files, one per line. Each line corresponds to a different sample.\n",
    "- A job script (e.g. `process.lsf`) that contains the commands to be run. This script will be executed multiple times, once for each sample. Note that **\"process\"** can be any analysis you want to run (e.g. `fastqc`, `multiqc`, `kraken2`, etc.).\n",
    "- A configuration file  (e.g. `config.sh`) that contains parameters, variables, and settings for the job script.\n",
    "- A job submission script, or launcher script, (e.g. `run_process.sh`) that submits the job array to the scheduler. It specifies the range of job indices to be run, which corresponds to the number of lines in the text file.\n",
    "\n",
    "## Scheduler\n",
    "A scheduler is a software that manages the resources of a computer cluster and allocates them to users. It is responsible for scheduling jobs, managing queues, and monitoring the status of jobs.\n",
    "\n",
    "> Note that all the notebooks in this repository assume you are using a **SLURM** (`fastqc.slurm`) or **LSF** (`fastqc.lsf`)  scheduler. If you are using a different scheduler, you will need to modify the job scripts and submission scripts accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fea0af",
   "metadata": {},
   "source": [
    "## Job script\n",
    "A few important points:\n",
    "1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "2. Our process runs on each of the fastq files in the $FASTQ_DIR\n",
    "3. We will copy the reports to our home directory to visualize these results (via ondemand Jupyter)\n",
    "4. Array is the number of samples, counting from zero   \n",
    "\n",
    "##### Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552cc4bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a template job script for LSF scheduler\n",
    "\n",
    "my_code = '''#!/bin/bash\n",
    "# --------------------------------------------------\n",
    "# Request resources here\n",
    "# --------------------------------------------------\n",
    "#BSUB -J process[1-15]%15             # job name, with array number to run in parallel\n",
    "#BSUB -n 2                            # number of CPUs required per task\n",
    "#BSUB -q shared_memory                # the queue to run on\n",
    "#BSUB -R \"span[hosts=1]\"              # number of hosts to spread the jobs across, 1 host used here\n",
    "#BSUB -R \"rusage[mem=4GB]\"            # required total memory for the job \n",
    "#BSUB -o \"./output.%J_%I.log\"         # standard output file (%J is job name, %I is the array number)\n",
    "#BSUB -e \"./error.%J_%I.log\"          # standard error file (%J is job ID, %I is the array number)\n",
    "#BSUB -W 10:00                        # time to run\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load modules here\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Execute commands here\n",
    "# --------------------------------------------------\n",
    "\n",
    "# echo for log\n",
    "echo \"job started\"; pwd; hostname; date\n",
    "\n",
    "# source the config file\n",
    "source ./config.sh\n",
    "\n",
    "# get sample ID\n",
    "export SAMPLE=`head -n +${LSB_JOBINDEX} $IN_LIST | tail -n 1`\n",
    "\n",
    "\n",
    "# echo for log\n",
    "echo \"job done\"; date\n",
    "'''\n",
    "\n",
    "with open('template.lsf', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcc961",
   "metadata": {},
   "source": [
    "## Config file\n",
    "All the jobs scripts in this repository use a configuration file (`config.sh`) to store parameters, variables, and settings. This file is sourced in the job scripts to make the variables available. Here we provide a template config file that you can modify for your own analysis.\n",
    "\n",
    "##### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb6879",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a template config file\n",
    "\n",
    "my_code = '''#!/bin/bash\n",
    "IN_LIST=/path_to_my_file/sample_list.txt\n",
    "FASTQC=/path_to_containers/container\n",
    "WORK_DIR=/my_dir_path/MY_ID/\n",
    "\n",
    "# Add more variables as needed\n",
    "# e.g. IN_DIR, OUT_DIR, etc.\n",
    "\n",
    "'''\n",
    "\n",
    "with open('template_config.sh', mode='w') as file:\n",
    "    file.write(my_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db502838",
   "metadata": {},
   "source": [
    "## Launcher script\n",
    "The launcher script is a bash script that submits the job array to the scheduler. It specifies the range of job indices to be run, which corresponds to the number of lines in the text file. Here we provide a template launcher script that you can modify for your own analysis.\n",
    "\n",
    "##### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af71702",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "my_code = '''#!/bin/bash -l\n",
    "\n",
    "# load job configuration\n",
    "source ./config.sh\n",
    "\n",
    "#\n",
    "# make sure sample file is in the right place\n",
    "#\n",
    "if [[ ! -f \"$IN_LIST\" ]]; then\n",
    "    echo \"$IN_LIST does not exist. Please provide the path for a list of datasets to process. Job terminated.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# get number of samples to process\n",
    "# the number of samples will be used to set the range of the job array\n",
    "export NUM_JOB=$(wc -l < \"$IN_LIST\")\n",
    "\n",
    "# submit job array\n",
    "echo \"launching process.lsf as a job.\"\n",
    "\n",
    "JOB_ID=`bsub -J \"process[1-$NUM_JOB]\" < process.lsf`\n",
    "\n",
    "'''\n",
    "\n",
    "with open('run_process.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb6f59",
   "metadata": {},
   "source": [
    "**Remember!** that in all these templates you will need to modify the word **\"process\"** to the name of the process you are running (e.g. `fastqc`, `multiqc`, `kraken2`, etc.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
