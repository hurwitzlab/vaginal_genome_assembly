{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7bac8",
   "metadata": {},
   "source": [
    "# Taxonomic Annotation of Reads and Human Removal\n",
    "\n",
    "This notebook will go through the workflow assigning taxonomy to reads from a microbiome\n",
    "\n",
    "Assign taxonomy to reads and separate out human\n",
    "1. Taxonomic assignment of reads using Kraken2\n",
    "2. Refinement of the taxonomic annotation using Bracken\n",
    "3. Separation of human and non-human reads using KrakenTools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebed36",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "You will need to rerun this section each time you come back to this notebook to reset all directories and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for your name and accessions\n",
    "# name is your output directory\n",
    "# accessions is a list of SRA accession ids, or your sample ids.\n",
    "id = \"MY_ID\"\n",
    "accessions = \"MY_ACCESSIONS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the working directory\n",
    "work_dir = \"/my_dir_path/\" + id + \"/02_taxonomy\"\n",
    "%cd $work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c830ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the fastq directory. This is where we put our fastq files with human contam removed.\n",
    "fastq_dir = \"/my_dir_path/\" + id + \"/01_qc_trimming/trimmed_reads\"\n",
    "data_dir = \"/my_dir_path/\" + id + \"/00_getting_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dffed",
   "metadata": {},
   "source": [
    "## Creating a config file\n",
    "Let's create a config file with all of the variables we will need in the scripts below. Then when we want to use these variables in the script, we will \"source\" the config file to set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config file with all of the variables you need\n",
    "# notice that now we are defining the tools here too, to make out scripts easier to read below\n",
    "# also, if we want to update to a newer version of the tool we can just edit here.\n",
    "!echo \"export ID=$id\" > config.sh\n",
    "!echo \"export ACCESSIONS=$accessions\" >> config.sh\n",
    "!echo \"export WORK_DIR=$work_dir\" >> config.sh\n",
    "!echo \"export DATA_DIR=$data_dir\" >> config.sh\n",
    "!echo \"export FASTQ_DIR=$fastq_dir\" >> config.sh\n",
    "!echo \"export KRAKEN2=/path_to_containers/kraken2:2.1.3--pl5321hdcf5f25_0.sif\" >> config.sh\n",
    "!echo \"export BRACKEN=/path_to_containers/bracken:2.8--py39h1f90b4d_1.sif\" >> config.sh\n",
    "!echo \"export KRAKENTOOLS=/path_to_containers/krakentools:1.2--pyh5e36f6f_0.sif\" >> config.sh\n",
    "!echo \"export DB_DIR=/path_to_databases/kraken2/k2_pluspf_20230605\" >> config.sh\n",
    "!echo \"export KMER_SIZE=100\" >> config.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeaabfe",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "\n",
    "Assigning taxonomy to the reads\n",
    "\n",
    "In this step, we will assign taxonomy to each of the reads in our microbiome (where possible). This script involves multiple steps in the annotation process including:\n",
    "\n",
    "1. Running Kraken2 to assign reads to organisms by taxonomic rank. \n",
    "2. Running Bracken a tool that refines the Kraken2 output to try to reassign reads to a higher taxonomic-level \n",
    "3. Separating out the reads based on their taxonomy using KrakenTools. human / non-human\n",
    "\n",
    "The final part in this analysis looks for any remaining human contamination in the files, after we align to the human genome using bowtie2. Do you see any reads reported as human? Try \"Blasting\" these to see if they are indeed human reads that we missed by the alignment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7e3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run Kraken, Bracken, and KrakenTools to assign taxonomy at the read-level.\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. Kraken2 runs on each of the fastq files in the trimmed/human screened $FASTQ_DIR\n",
    "# 3. The results will be written into our $WORK_DIR\n",
    "# 4. Notice that we are asking for alot more resource (24 cores and 5G of memory per core)\n",
    "# But, runtime will likely be much less.\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --nodes=1             \n",
    "#SBATCH --time=10:00:00   \n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=your_account\n",
    "#SBATCH --array=0-15                         \n",
    "#SBATCH --output=10A_read_taxonomy-%a.out\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem-per-cpu=5G  \n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source $SLURM_SUBMIT_DIR/config.sh\n",
    "names=($(cat $DATA_DIR/$ACCESSIONS))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "### reads with human removed to match to the reference database\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_R1_001.fastq.gz\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_R2_001.fastq.gz\n",
    "\n",
    "KRAKEN_OUTDIR=${WORK_DIR}/out_reads_taxonomy\n",
    "OUTDIR=${KRAKEN_OUTDIR}/${SAMPLE_ID}\n",
    "HUMAN_READ_DIR=${OUTDIR}/human_reads\n",
    "NONHUMAN_READ_DIR=${OUTDIR}/nonhuman_reads\n",
    "\n",
    "### create the outdir if it does not exist\n",
    "if [[ ! -d \"$KRAKEN_OUTDIR\" ]]; then\n",
    "  echo \"$KRAKEN_OUTDIR does not exist. Directory created\"\n",
    "  mkdir $KRAKEN_OUTDIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$OUTDIR\" ]]; then\n",
    "  echo \"$OUTDIR does not exist. Directory created\"\n",
    "  mkdir $OUTDIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$HUMAN_READ_DIR\" ]]; then\n",
    "  echo \"$HUMAN_READ_DIR does not exist. Directory created\"\n",
    "  mkdir $HUMAN_READ_DIR\n",
    "fi\n",
    "\n",
    "if [[ ! -d \"$NONHUMAN_READ_DIR\" ]]; then\n",
    "  echo \"$NONHUMAN_READ_DIR does not exist. Directory created\"\n",
    "  mkdir $NONHUMAN_READ_DIR\n",
    "fi\n",
    "\n",
    "# check input\n",
    "echo ${PAIR1}\n",
    "echo ${PAIR2}\n",
    "echo ${OUTDIR}\n",
    "\n",
    "apptainer run ${KRAKEN2} kraken2 --db ${DB_DIR} --paired \\\n",
    "  --classified-out ${OUTDIR}/cseqs#.fq --output ${OUTDIR}/kraken_results.txt \\\n",
    "  --report ${OUTDIR}/kraken_report.txt --use-names --threads ${SLURM_CPUS_PER_TASK} \\\n",
    "  ${PAIR1} ${PAIR2}\n",
    "\n",
    "# refine hits with Bracken\n",
    "REPORT=\"${OUTDIR}/kraken_report.txt\"\n",
    "RESULTS=\"${OUTDIR}/kraken_results.txt\"\n",
    "apptainer run ${BRACKEN} est_abundance.py -i ${REPORT} -o ${OUTDIR}/bracken_results.txt -k ${DB_DIR}/database${KMER_SIZE}mers.kmer_distrib\n",
    "\n",
    "# get human and non-human reads (microbial)\n",
    "TAXID=9606\n",
    "HUMAN_R1=\"${HUMAN_READ_DIR}/r1.fq\"\n",
    "HUMAN_R2=\"${HUMAN_READ_DIR}/r2.fq\"\n",
    "\n",
    "BRACKEN_REPORT=\"${OUTDIR}/kraken_report_bracken_species.txt\"\n",
    "BRACKEN_RESULTS=\"${OUTDIR}/bracken_results.txt\"\n",
    "\n",
    "apptainer run ${KRAKENTOOLS} extract_kraken_reads.py -k ${RESULTS} \\\n",
    " -r ${BRACKEN_REPORT} -s1 ${PAIR1} -s2 ${PAIR2} --taxid ${TAXID} \\\n",
    " -o ${HUMAN_R1} -o2 ${HUMAN_R2} --include-children --fastq-output \n",
    "\n",
    "gzip ${HUMAN_READ_DIR}/r1.fq\n",
    "gzip ${HUMAN_READ_DIR}/r2.fq\n",
    "\n",
    "### selects all reads NOT from a given set of Kraken taxids (and all children)\n",
    "\n",
    "NONHUMAN_R1=\"${NONHUMAN_READ_DIR}/r1.fq\"\n",
    "NONHUMAN_R2=\"${NONHUMAN_READ_DIR}/r2.fq\"\n",
    "\n",
    "apptainer run ${KRAKENTOOLS} extract_kraken_reads.py -k ${RESULTS} \\\n",
    " -r ${BRACKEN_REPORT} -s1 ${PAIR1} -s2 ${PAIR2} --taxid ${TAXID} \\\n",
    " -o ${NONHUMAN_R1} -o2 ${NONHUMAN_R2} --include-children \\\n",
    " --exclude --fastq-output \n",
    "\n",
    "gzip ${NONHUMAN_READ_DIR}/r1.fq\n",
    "gzip ${NONHUMAN_READ_DIR}/r2.fq\n",
    "\n",
    "echo \"Finished `date`\"\n",
    "\n",
    "'''\n",
    "\n",
    "with open('02A_taxonomy.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfaf63",
   "metadata": {},
   "source": [
    "## Step 2: Putting it all together\n",
    "\n",
    "Once you have created the the run scripts, you are ready to put them together in a pipeline to run each of the steps one by one. Notice which steps are dependent on the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1751d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the launcher script to kick off our pipeline.\n",
    "\n",
    "my_code = '''#! /bin/bash\n",
    "\n",
    "# 02A_taxonomy: jid1 has no dependencies\n",
    "job1=$(sbatch 02A_taxonomy.sh)\n",
    "jid1=$(echo $job1 | sed 's/^Submitted batch job //')\n",
    "echo $jid1\n",
    "\n",
    "'''\n",
    "\n",
    "with open('02_launch_pipeline.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pipeline script executable\n",
    "!chmod +x *.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's run it!\n",
    "!./02_launch_pipeline.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb693f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your user id\n",
    "# Note that this will take some time to run, so go get a coffee!\n",
    "!squeue --user=$id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
