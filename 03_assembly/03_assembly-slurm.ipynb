{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7bac8",
   "metadata": {},
   "source": [
    "# Assembling reads into contigs (fragments of a genome)\n",
    "\n",
    "This notebook will go through the workflow for using the unicycler assembly tool. In this section we are going to assemble our reads into contigs. Contigs are fragments of DNA that represent parts of a genome. If you are lucky, you might even be able to assemble an entire genome in a single contig! But, most of the time, contigs are just part of a genome with missing fragments in between contigs that prevent you from assembling the entire genome.\n",
    "\n",
    "-----------\n",
    "\n",
    "Sections:\n",
    "\n",
    "1. Run Unicycler to create an assembled genome.\n",
    "\n",
    "-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebed36",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Before we get started you will need to set several variables that we will use throughout this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for your user id and accessions\n",
    "netid = \"MY_ID\"\n",
    "accessions = \"MY_ACCESSIONS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the working directory\n",
    "work_dir = \"/my_dir_path/\" + id + \"/03_assembly\"\n",
    "%cd $work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the fastq directory. This is where we have our fastq files with human contam removed.\n",
    "fastq_dir = \"/my_dir_path/\" + id + \"/02_taxonomy\"\n",
    "data_dir = \"/my_dir_path/\" + id + \"/00_getting_data\"\n",
    "out_dir = work_dir + \"/out_unicycler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dffed",
   "metadata": {},
   "source": [
    "## Creating a config file\n",
    "The scripts below executes code that requires certain variables to be set. So we don't need to edit the code in the script, we are going to use a config file that defines all of these variables for us. Then when we want to use these variables in the script, we will \"source\" the config file to set the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config file with all of the variables you need\n",
    "# notice that we will assemble the reads that are both trimmed and have human removed.\n",
    "!echo \"export ID=$id\" > config.sh\n",
    "!echo \"export ACCESSIONS=$accessions\" >> config.sh\n",
    "!echo \"export DATA_DIR=$data_dir\" >> config.sh\n",
    "!echo \"export FASTQ_DIR=$fastq_dir\" >> config.sh\n",
    "!echo \"export OUT_UNI=$out_dir\" >> config.sh\n",
    "!echo \"export UNICYCLER=/path_to_containers/unicycler:0.5.0--py39h4e691d4_3.sif\" >> config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0517df3",
   "metadata": {},
   "source": [
    "### Data Management\n",
    "\n",
    "We'll be creating an assembly based on the trimmed/human removed reads. Let's setup the output directory ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbf652",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $work_dir/out_megahit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c6eed",
   "metadata": {},
   "source": [
    "## Step 1: Running Unicycler to create contigs\n",
    "\n",
    "Let's create an assembly of all of the genomes in your microbiomes using megahit. This assembler is fast, and uses less resources than other metagenome assemblers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0721664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run megahit\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command\n",
    "# 2. unicycler runs on each of the fastq files in the trimmed/human screened $FASTQ_DIR\n",
    "# 3. The results will be written into our $OUT_UNI directory\n",
    "# 4. Notice that we are asking for alot more resource (28 cores and 5G of memory per core)\n",
    "\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --output=03_assembly-%a.out\n",
    "#SBATCH --account=your_account\n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --cpus-per-task=28\n",
    "#SBATCH --mem-per-cpu=5gb\n",
    "#SBATCH --array=0-15\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $DATA_DIR/$ACCESSIONS))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "NO_HUMAN=${FASTQ_DIR}/out_reads_taxonomy/${SAMPLE_ID}/nonhuman_reads\n",
    "PAIR1=${NO_HUMAN}/r1.fq.gz\n",
    "PAIR2=${NO_HUMAN}/r2.fq.gz\n",
    "\n",
    "#add threads flag & exposition on adding threads or it runs inefficient\n",
    "apptainer run ${UNICYCLER} unicycler -1 ${PAIR1} -2 ${PAIR2} -o ${OUT_UNI}/${names[${SLURM_ARRAY_TASK_ID}]} --threads 28\n",
    "\n",
    "'''\n",
    "\n",
    "with open('03_assembly-lsf.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the 03_assembly.sh script?\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d07384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the launcher script to kick off our pipeline.\n",
    "\n",
    "my_code = '''#! /bin/bash\n",
    "\n",
    "# 03_assembly: first job - no dependencies\n",
    "job1=$(sbatch 03_assembly.sh)\n",
    "jid1=$(echo $job1 | sed 's/^Submitted batch job //')\n",
    "echo $jid1\n",
    "\n",
    "'''\n",
    "\n",
    "with open('03_launch_pipeline-lsf.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pipeline script executable\n",
    "!chmod +x *.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's run it!\n",
    "!./03_launch_pipeline-lsf.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a99f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your netid\n",
    "# Note that this will take some time to run, so go get a coffee!\n",
    "!squeue --user=$id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83501ab5",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
