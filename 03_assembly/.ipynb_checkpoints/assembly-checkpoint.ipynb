{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7bac8",
   "metadata": {},
   "source": [
    "# Assembling reads into contigs\n",
    "\n",
    "This notebook will go through the workflow for using the spades, unicycler, and megahit assembly tools. In this section we are going to assemble our reads into contigs. Contigs are fragments of DNA that represent parts of a genome. If you are lucky, you might even be able to assemble an entire genome in a single contig! But, most of the time, contigs are just part of a genome with missing fragments in between contigs that prevent you from assembling the entire genome.\n",
    "\n",
    "1. An introduction to [Spades](https://cab.spbu.ru/files/release3.12.0/manual.html)\n",
    "2. An introduction to [Megahit](https://github.com/voutcn/megahit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebed36",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "You will need to rerun this section each time you come back to this notebook to reset all directories and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for your netid and xfile\n",
    "netid = \"YOUR_NETID\"\n",
    "xfile = \"YOUR_XFILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d388ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the working directory\n",
    "work_dir = \"/xdisk/bhurwitz/bh_class/\" + netid + \"/03_assembly\"\n",
    "%cd $work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dffed",
   "metadata": {},
   "source": [
    "## Creating a config file\n",
    "The scripts below executes code that requires certain variables to be set. So we don't need to edit the code in the script, we are going to use a config file that defines all of these variables for us. Then when we want to use these variables in the script, we will \"source\" the config file to set the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0517df3",
   "metadata": {},
   "source": [
    "### Data Management\n",
    "\n",
    "We'll be creating two assemblies based on the trimmed/human removed reads. Let's setup the output directories ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbf652",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $work_dir/out_spades\n",
    "!mkdir $work_dir/out_megahit\n",
    "!mkdir $work_dir/out_unicycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config file with all of the variables you need\n",
    "# notice that we will assemble the reads that are both trimmed and have human removed.\n",
    "!echo \"export NETID=$netid\" > config.sh\n",
    "!echo \"export XFILE=$xfile\" >> config.sh\n",
    "!echo \"export XFILE_DIR=/xdisk/bhurwitz/bh_class/$netid/01_qc_trimming\" >> config.sh\n",
    "!echo \"export FASTQ_DIR=/xdisk/bhurwitz/bh_class/$netid/02_taxonomy\" >> config.sh\n",
    "!echo \"export OUT_SPADES=/xdisk/bhurwitz/bh_class/$netid/assignments/08_assembly/out_spades\" >> config.sh\n",
    "!echo \"export OUT_MEGA=/xdisk/bhurwitz/bh_class/$netid/assignments/08_assembly/out_megahit\" >> config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aabce3",
   "metadata": {},
   "source": [
    "## Step 1: Running Metaspades to create contigs\n",
    "\n",
    "You will be assembling your reads using a program called spades, that has the metaspades.py program within it for assembling metagenomes comprised of multiple organisms.\n",
    "\n",
    "It's important to note that this assembler is memory intensive, and for large files it takes a lot of resource and time. A common error for large files is running out of memory to complete the job in the HPC. If needed, we can modify our script if it requires more memory. \n",
    "\n",
    "Puma can have 94 CPUs @ 5gb/CPU <br>\n",
    "Ocelote can have 28 CPUs @ 6gb/CPU\n",
    "\n",
    "This [HPC documentation](https://public.confluence.arizona.edu/display/UAHPC/Running+Jobs+with+SLURM) is handy to have as you edit your scripts and use different HPCs within UA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeae218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run metaspades\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. metaspades runs on each of the fastq files in the trimmed $FASTQ_DIR\n",
    "# 3. The results will be written into our $OUT_SPADES directory\n",
    "# 4. Notice that we are asking for alot more resource (28 cores and 5G of memory per core), we are also asking for more time (24 hours)\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --output=Job-spades-%a.out\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --cpus-per-task=28\n",
    "#SBATCH --mem-per-cpu=5gb\n",
    "#SBATCH --array=0-4\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq*\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq*\n",
    "\n",
    "#add threads flag & exposition on adding threads or it runs inefficient\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/spades:3.15.5--h95f258a_1.sif metaspades.py \\\n",
    "   -o ${OUT_SPADES}/${names[${SLURM_ARRAY_TASK_ID}]} \\\n",
    "   --pe1-1 ${PAIR1} \\\n",
    "   --pe1-2 ${PAIR2}\n",
    "'''\n",
    "\n",
    "with open('run_metaspades.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e42306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the rrun_metaspades.sh script?\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe884278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run sbatch to run metaspades on each of the FASTQ files\n",
    "# Remember that this may take a while to run, so take a break, \n",
    "# and get a coffee.\n",
    "!sbatch ./run_metaspades.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your netid\n",
    "!squeue --user=$netid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e70ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once your jobs have run (or are running) you can check the progress\n",
    "# and also look for errors in the *out files\n",
    "# For example, you can look at Job-spades-0.out\n",
    "!ls\n",
    "!cat Job-spades-0.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you see a contigs file?\n",
    "!ls $work_dir/out_spades/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b30b51",
   "metadata": {},
   "source": [
    "Great job! You should now have assemblies from metaspades. You can kick off the assembly below with megahit without disrupting your work from above. Go for it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c6eed",
   "metadata": {},
   "source": [
    "## Step 2: Running Megahit to create contigs\n",
    "\n",
    "We'll now repeat the process using megahit -- A different algorithm to assemble your contigs. This assembler works a lot faster, using less resources but isn't as accurate as spades. If you find spades crashing due to memory-out errors megahit will be able to assemble the bigger read files. \n",
    "\n",
    "Other options we'll explore in later notebooks are removing reads based on a reference genome database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0721664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script to run metaspades\n",
    "# A few important points:\n",
    "# 1. We are using the variables from the config file via the `source ./config.sh` command in the script.\n",
    "# 2. metaspades runs on each of the fastq files in the trimmed $FASTQ_DIR\n",
    "# 3. The results will be written into our $OUT_SPADES directory\n",
    "# 4. Notice that we are asking for alot more resource (28 cores and 5G of memory per core), we are also asking for more time (24 hours)\n",
    "my_code = '''#!/bin/bash\n",
    "#SBATCH --output=Job-megahit-%a.out\n",
    "#SBATCH --account=bh_class\n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --cpus-per-task=28\n",
    "#SBATCH --mem-per-cpu=5gb\n",
    "#SBATCH --array=0-4\n",
    "\n",
    "pwd; hostname; date\n",
    "\n",
    "source ./config.sh\n",
    "names=($(cat $XFILE_DIR/$XFILE))\n",
    "\n",
    "SAMPLE_ID=${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "PAIR1=${FASTQ_DIR}/${SAMPLE_ID}_1.fastq*\n",
    "PAIR2=${FASTQ_DIR}/${SAMPLE_ID}_2.fastq*\n",
    "\n",
    "apptainer run /contrib/singularity/shared/bhurwitz/megahit:1.2.9--h5b5514e_3.sif megahit \\\n",
    "   -1 ${PAIR1} \\\n",
    "   -2 ${PAIR2} \\\n",
    "   -o ${OUT_MEGA}/${names[${SLURM_ARRAY_TASK_ID}]}\n",
    "'''\n",
    "\n",
    "with open('run_megahit.sh', mode='w') as file:\n",
    "    file.write(my_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should be in your working directory when you run this script\n",
    "# do you see your config.sh file, and the rrun_megahit.sh script?\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e632a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run sbatch to run megahit on each of the FASTQ files\n",
    "# Remember that this may take a while to run, so take a break, \n",
    "# and get a coffee.\n",
    "!sbatch ./run_megahit.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a99f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check if it is running using the squeue command\n",
    "# Check for all jobs under your netid\n",
    "!squeue --user=$netid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once your jobs have run (or are running) you can check the progress\n",
    "# and also look for errors in the *out files\n",
    "# For example, you can look at Job-megahit-0.out\n",
    "!ls\n",
    "!cat Job-megahit-0.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you see a final_contigs.fa file?\n",
    "!ls $work_dir/out_megahit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83501ab5",
   "metadata": {},
   "source": [
    "## Final Step\n",
    "Copy your notebook to the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ~/08_assembly.ipynb $work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672d8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
